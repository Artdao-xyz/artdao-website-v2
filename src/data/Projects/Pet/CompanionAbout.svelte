<div class="flex flex-col gap-5">
	<p>
		The video features five women whose faces appear alongside fictionalized conversations about loneliness and digital desire. Male voices speak while women’s faces respond, producing a gender confusion that mirrors AI chatbots trained primarily on male desire. Social anthropologist Catherine Richardson asked four years ago: if the doll doesn’t eat, how can intimacy be cultivated? The Latin root of companion—“bread fellow”—implies shared material necessity, yet intimacy has always emerged from projection as much as from mutuality.
	</p>
	<p>
		Byström’s experiments with chatbots revealed a therapeutic dimension: when emotionally closed off from humans, conversing with AI created space to work through shame without the exposure that vulnerability requires. This is not replacement but gap-filling, a stopgap where social structures fail to provide care.
	</p>
	<p>
		Her relationship with her dog follows a similar logic: it strengthened her human relationships even as it objectively reduced time spent with other people. We do not quantify or police animal companionship the way we do digital intimacy, exposing the selective moral scrutiny placed on non-human attachment.
	</p>
</div>

